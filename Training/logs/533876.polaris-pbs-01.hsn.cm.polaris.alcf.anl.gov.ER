
Lmod is automatically replacing "nvhpc/21.9" with "gcc/11.2.0".


Lmod is automatically replacing "PrgEnv-nvhpc/8.3.3" with "PrgEnv-gnu/8.3.3".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-mpich/8.1.16

cpubind:list x3212c0s7b1n0 pid 61879 rank 12 0: mask 0x0001ffff
cpubind:list x3212c0s7b1n0 pid 61881 rank 13 1: mask 0x0001ffff
cpubind:list x3212c0s7b1n0 pid 61882 rank 14 2: mask 0x0001ffff
cpubind:list x3212c0s7b1n0 pid 61884 rank 15 3: mask 0x0001ffff
cpubind:list x3212c0s7b0n0 pid 53788 rank 9 1: mask 0x0001ffff
cpubind:list x3212c0s7b0n0 pid 53789 rank 10 2: mask 0x0001ffff
cpubind:list x3212c0s7b0n0 pid 53787 rank 8 0: mask 0x0001ffff
cpubind:list x3212c0s7b0n0 pid 53790 rank 11 3: mask 0x0001ffff
cpubind:list x3212c0s37b0n0 pid 54452 rank 5 1: mask 0x0001ffff
cpubind:list x3212c0s37b0n0 pid 54451 rank 4 0: mask 0x0001ffff
cpubind:list x3212c0s37b0n0 pid 54454 rank 7 3: mask 0x0001ffff
cpubind:list x3212c0s37b0n0 pid 54453 rank 6 2: mask 0x0001ffff
cpubind:list x3209c0s7b1n0 pid 52707 rank 2 2: mask 0x0001ffff
cpubind:list x3209c0s7b1n0 pid 52705 rank 0 0: mask 0x0001ffff
cpubind:list x3209c0s7b1n0 pid 52706 rank 1 1: mask 0x0001ffff
cpubind:list x3209c0s7b1n0 pid 52708 rank 3 3: mask 0x0001ffff
2023-06-14 01:38:31.776106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.776106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.776106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.781474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.934692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.934696: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.934706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:31.934706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.270705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.270702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.270702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.270698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.408808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.408810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.408818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:32.408816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:38:33.597036: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.597039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.597038: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.597301: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.626768: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.626765: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.626760: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:33.626761: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.413932: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.413933: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.413933: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.414436: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.522327: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.522330: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.522336: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:38:34.522339: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-14 01:39:41.390507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.463272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.467590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.472904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0
2023-06-14 01:39:41.562688: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.651829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.752069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.753899: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.760403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0
2023-06-14 01:39:41.820092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0
2023-06-14 01:39:41.861764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:41.870300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0
2023-06-14 01:39:41.930554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0
2023-06-14 01:39:41.988530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:42.064189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:42.072519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0
2023-06-14 01:39:42.077422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0, compute capability: 8.0
2023-06-14 01:39:42.131640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:42.185388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0
2023-06-14 01:39:42.235705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:42.326406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:42.477604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:42.565246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:42.663406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0
2023-06-14 01:39:42.667524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:42.753357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0, compute capability: 8.0
2023-06-14 01:39:42.870780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:42.919226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:43.098377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:43.307358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:44.615225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-14 01:39:45.042670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38345 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2023-06-14 01:39:49.472103: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.494506: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.526943: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.526955: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.641470: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.656001: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.664343: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.805196: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.815253: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.850925: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:49.872452: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:50.028787: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:50.257737: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:50.312841: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:50.517268: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 01:39:52.434259: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-06-14 05:18:14.714573: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715086: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715216: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715242: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715323: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715347: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715398: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715476: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715588: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715693: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715806: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.715873: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716017: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716044: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716053: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716071: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716083: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.716091: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718072: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718556: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718614: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718657: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718699: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718735: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718774: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718821: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718861: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.718927: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.721774: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.721906: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722067: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722110: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722242: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722287: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722378: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722508: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722669: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722819: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.722966: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723096: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723298: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723348: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723365: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723400: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:493 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723424: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.723437: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.735617: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.736035: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.752760: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.753136: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.772901: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.772939: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.804717: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
2023-06-14 05:18:14.804738: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at mpi_ops.cc:725 : UNKNOWN: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pyt22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pyt2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/p22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/hon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/ython3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 125, in allreduce
      summed_tensor_compressed = _allreduce(tensor_compressed, op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 127, in _allreduce
      return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op,
    File "<string>", line 107, in horovod_allreduce
Node: 'DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0'
Detected at node 'DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
  hon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datasciencconda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
e/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 125, in allreduce
      summed_tensor_compressed = _allreduce(tensor_compressed, op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 127, in _allreduce
      return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op,
    File "<string>", line 107, in horovod_allreduce
Node: 'DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_18/HorovodAllreduce_grads_22_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pytho22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pyt22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pytn3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0'
Detected at node 'DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/condhon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/hon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/a/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/libconda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond/HorovodAllgather_grads_1_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pyt22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pytTraceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/hon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascienc22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datasciencconda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3e/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mcondhon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/e/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mcond/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
a3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3a3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/20Traceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pyt22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/pytTraceback (most recent call last):
  File "smiles_regress_transformer_run.py", line 49, in <module>
    history = train_and_callbacks.training(
  File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
    history = model.fit(
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:

Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/hon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascienc22-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datasciencconda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3e/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mcondhon3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
Detected at node 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0' defined at (most recent call last):
    File "smiles_regress_transformer_run.py", line 49, in <module>
      history = train_and_callbacks.training(
    File "/lus/grand/projects/datascience/avasan/Benchmarks_ST_Publication/ST_Revised_Train_multiReceptors/3CLPro_7BQY_A_1_F/ST_funcs/smiles_regress_transformer_funcs.py", line 424, in training
      history = model.fit(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1564, in fit
      tmp_logs = self.train_function(iterator)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1201, in train_function
      for _ in tf.range(self._steps_per_execution):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1202, in train_function
      outputs = step_function(self, iterator)
    File "/soft/datascience/e/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mcond/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
a3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
	 [[while/loop_body_control/_126/_19]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1146, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 1135, in run_step
      outputs = model.train_step(data)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/engine/training.py", line 997, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 576, in minimize
      grads_and_vars = self._compute_gradients(
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 94, in _compute_gradients
      allreduced_grads = self._allreduce(grads, weights)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/_keras/__init__.py", line 124, in _allreduce
      return self._allreduce_grads(grads, vars)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 416, in allreduce_grads
      if groups is not None:
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 457, in allreduce_grads
      op=op,
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 297, in _allreduce_cond
      tf.convert_to_tensor(process_set.included() and process_set.size() > 1)),
    File "/soft/datascience/conda/2022-09-08/mconda3a3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 106, in allreduce
      indices = allgather(tensor.indices, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_4_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 288, in allreduce_fn
      return allreduce(tensor, *args, process_set=process_set, **kwargs)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 95, in allreduce
      if isinstance(tensor, tf.IndexedSlices):
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/__init__.py", line 105, in allreduce
      values = allgather(tensor.values, process_set=process_set)
    File "/soft/datascience/conda/2022-09-08/mconda3/lib/python3.8/site-packages/horovod/tensorflow/mpi_ops.py", line 223, in allgather
      return MPI_LIB.horovod_allgather(tensor, name=name,
    File "<string>", line 393, in horovod_allgather
Node: 'DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0'
2 root error(s) found.
  (0) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
	 [[while/LoopCond/_116/_216]]
  (1) UNKNOWN:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.
	 [[{{node DistributedAdam_Allreduce/cond_1/HorovodAllgather_grads_3_0}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13830]
x3209c0s7b1n0.hsn.cm.polaris.alcf.anl.gov: rank 1 exited with code 1
